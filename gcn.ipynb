{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     budget    imdb_id      revenue vote_average  movieId     imdbId   tmdbId  \\\n",
      "0  30000000  tt0758752  102820008.0          7.0    82167  tt0758752  43347.0   \n",
      "1   4600000  tt0382383    6700000.0          6.3    48239  tt0382383  43410.0   \n",
      "2  24000000  tt0464154   83188165.0          5.3    79879  tt0464154  43593.0   \n",
      "3    600000  tt0281680    1023156.0          5.2    59366  tt0281680  43664.0   \n",
      "4  16000000  tt0339727     174318.0          5.6     8996  tt0339727  43670.0   \n",
      "\n",
      "                                               title  \\\n",
      "0                        Love and Other Drugs (2010)   \n",
      "1                                        Yuva (2004)   \n",
      "2                        Piranha (Piranha 3D) (2010)   \n",
      "3  Bread, My Sweet, The (a.k.a. Wedding for Bella...   \n",
      "4                                   Stateside (2004)   \n",
      "\n",
      "                         genres  \n",
      "0          Comedy|Drama|Romance  \n",
      "1  Action|Adventure|Crime|Drama  \n",
      "2        Action|Horror|Thriller  \n",
      "3                 Drama|Romance  \n",
      "4                         Drama  \n",
      "   userId  movieId  rating   timestamp\n",
      "0       1        1     4.0  1225734739\n",
      "1       1      110     4.0  1225865086\n",
      "2       1      158     4.0  1225733503\n",
      "4       1      356     5.0  1225735119\n",
      "8       1     1049     3.0  1225734079\n",
      "2986\n",
      "17627731\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def read_movies():\n",
    "    # read csv with movies for budget and imdb_id\n",
    "    columns_of_interest = ['budget', 'imdb_id', 'revenue', 'vote_average']\n",
    "    data = []\n",
    "    with open('./data/movie_data_tmbd.csv', 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter='|')\n",
    "        for row in reader:\n",
    "            extracted_row = {col: row[col] for col in columns_of_interest}\n",
    "            data.append(extracted_row)\n",
    "\n",
    "    movies_budget_df = pd.DataFrame(data)\n",
    "    movies_budget_df = movies_budget_df.fillna({\n",
    "        'budget': 0,\n",
    "        'imdb_id': '',\n",
    "        'title': ''\n",
    "    })\n",
    "\n",
    "    # merge movie budget with id\n",
    "    link_df = pd.read_csv(\"./data/links.csv\")\n",
    "    link_df['imdbId'] = link_df['imdbId'].apply(lambda x: f'tt0{int(x)}')\n",
    "\n",
    "    movies_id_df = pd.merge(movies_budget_df, link_df, left_on='imdb_id', right_on='imdbId', how='inner')\n",
    "    movies_id_df['budget'] = pd.to_numeric(movies_id_df['budget'])\n",
    "    movies_id_df['revenue'] = pd.to_numeric(movies_id_df['revenue'])\n",
    "    movies_id_df = movies_id_df[movies_id_df.budget != 0]\n",
    "    movies_id_df = movies_id_df[movies_id_df.revenue != 0]\n",
    "\n",
    "    movies_info_df = pd.read_csv(\"./data/movies.csv\")\n",
    "    movies_df = pd.merge(movies_id_df, movies_info_df, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    ratings_df = pd.read_csv(\"./data/ratings.csv\")\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(movies_df['movieId'])]\n",
    "\n",
    "    return movies_df, ratings_df\n",
    "\n",
    "movies_df, ratings_df = read_movies()\n",
    "print(movies_df.head())\n",
    "print(ratings_df.head())\n",
    "print(len(movies_df))\n",
    "print(len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2986, 20])\n"
     ]
    }
   ],
   "source": [
    "genres = movies_df['genres'].str.get_dummies('|')\n",
    "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
    "print(movie_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986\n",
      "2986\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings_df['movieId'].unique()))\n",
    "print(len(movies_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 17627731])\n"
     ]
    }
   ],
   "source": [
    "# construct a compact representation of the data\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "unique_movie_id = ratings_df['movieId'].unique()\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': unique_movie_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_movie_id)),\n",
    "})\n",
    "\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id, on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedId'].values)\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id, on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedId'].values)\n",
    "\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
    "print(edge_index_user_to_movie.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_movie_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index_user_to_movie[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[323487] },\n",
      "  movie={\n",
      "    node_id=[2986],\n",
      "    x=[2986, 20],\n",
      "  },\n",
      "  (user, rates, movie)={ edge_index=[2, 17627731] },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 17627731] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "# save node indices\n",
    "data['user'].node_id = torch.arange(len(unique_user_id))\n",
    "data['movie'].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# add node features\n",
    "data['movie'].x = movie_feat\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index_user_to_movie\n",
    "\n",
    "# we also need reverse edges from movies to users TODO: why?\n",
    "data = T.ToUndirected()(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[323487] },\n",
      "  movie={\n",
      "    node_id=[2986],\n",
      "    x=[2986, 20],\n",
      "  },\n",
      "  (user, rates, movie)={ edge_index=[2, 17627731] },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 17627731] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = HeteroData()# Save node indices:\n",
    "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "data[\"movie\"].node_id = torch.arange(len(movies_df))# Add the node features and edge indices:\n",
    "data[\"movie\"].x = movie_feat\n",
    "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie# We also need to make sure to add the reverse edges from movies to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "data = T.ToUndirected()(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
    "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"), \n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[11512],\n",
      "    n_id=[11512],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[2498],\n",
      "    x=[2498, 20],\n",
      "    n_id=[2498],\n",
      "    num_sampled_nodes=[3],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 12947],\n",
      "    edge_label=[192],\n",
      "    edge_label_index=[2, 192],\n",
      "    e_id=[12947],\n",
      "    num_sampled_edges=[2],\n",
      "    input_id=[64],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 34907],\n",
      "    e_id=[34907],\n",
      "    num_sampled_edges=[2],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create mini-batching so it fits on the gpu\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "edge_label_index = train_data['user', 'rates', 'movie'].edge_label_index\n",
    "edge_label = train_data['user', 'rates', 'movie'].edge_label\n",
    "\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10], #TODO: this can and should be changed\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=(('user', 'rates', 'movie'), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size = 64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(train_loader))\n",
    "print(sampled_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['user', 'rates', 'movie'].edge_label.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (movie_lin): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (user_emb): Embedding(323487, 64)\n",
      "  (movie_emb): Embedding(2986, 64)\n",
      "  (gnn): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    # final classifier, applies dot product on tail and head embeddings for prediction\n",
    "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    # TODO: add data in function header?\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.movie_lin = torch.nn.Linear(20, hidden_dim) # TODO: thats the number of neighbors?\n",
    "        self.user_emb = torch.nn.Embedding(data['user'].num_nodes, hidden_dim)\n",
    "        self.movie_emb = torch.nn.Embedding(data['movie'].num_nodes, hidden_dim)\n",
    "        self.gnn = GNN(hidden_dim)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data:HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "            \"user\": self.user_emb(data['user'].node_id),\n",
    "            \"movie\": self.movie_lin(data['movie'].x) + self.movie_emb(data['movie'].node_id),\n",
    "        }\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"movie\"],\n",
    "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "model = Model(hidden_dim=64)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['user', 'rates', 'movie'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 66104/66104 [08:59<00:00, 122.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss:1.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 66104/66104 [08:59<00:00, 122.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss:1.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        label = sampled_data['user', 'rates', 'movie'].edge_label\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) + pred.numel() # TODO: numel?!\n",
    "        total_examples += pred.numel()\n",
    "    print(f'Epoch: {epoch:03d}, Loss:{total_loss/total_examples:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation seed edges:\n",
    "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=3 * 128,\n",
    "    shuffle=False,\n",
    ")\n",
    "sampled_data = next(iter(val_loader))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13772/13772 [01:16<00:00, 178.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation AUC: 0.9670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = []\n",
    "ground_truths = []\n",
    "for sampled_data in tqdm.tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        sampled_data.to(device)\n",
    "        preds.append(model(sampled_data))\n",
    "        ground_truths.append(sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
    "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "auc = roc_auc_score(ground_truth, pred)\n",
    "print()\n",
    "print(f\"Validation AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
