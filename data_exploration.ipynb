{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     budget    imdb_id      revenue vote_average  movieId     imdbId   tmdbId  \\\n",
      "0  30000000  tt0758752  102820008.0          7.0    82167  tt0758752  43347.0   \n",
      "1   4600000  tt0382383    6700000.0          6.3    48239  tt0382383  43410.0   \n",
      "2  24000000  tt0464154   83188165.0          5.3    79879  tt0464154  43593.0   \n",
      "3    600000  tt0281680    1023156.0          5.2    59366  tt0281680  43664.0   \n",
      "4  16000000  tt0339727     174318.0          5.6     8996  tt0339727  43670.0   \n",
      "\n",
      "                                               title  \\\n",
      "0                        Love and Other Drugs (2010)   \n",
      "1                                        Yuva (2004)   \n",
      "2                        Piranha (Piranha 3D) (2010)   \n",
      "3  Bread, My Sweet, The (a.k.a. Wedding for Bella...   \n",
      "4                                   Stateside (2004)   \n",
      "\n",
      "                         genres  \n",
      "0          Comedy|Drama|Romance  \n",
      "1  Action|Adventure|Crime|Drama  \n",
      "2        Action|Horror|Thriller  \n",
      "3                 Drama|Romance  \n",
      "4                         Drama  \n",
      "   userId  movieId  rating   timestamp\n",
      "0       1        1     4.0  1225734739\n",
      "1       1      110     4.0  1225865086\n",
      "2       1      158     4.0  1225733503\n",
      "4       1      356     5.0  1225735119\n",
      "8       1     1049     3.0  1225734079\n",
      "2986\n",
      "17627731\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def read_movies():\n",
    "    # read csv with movies for budget and imdb_id\n",
    "    columns_of_interest = ['budget', 'imdb_id', 'revenue', 'vote_average']\n",
    "    data = []\n",
    "    with open('./data/movie_data_tmbd.csv', 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter='|')\n",
    "        for row in reader:\n",
    "            extracted_row = {col: row[col] for col in columns_of_interest}\n",
    "            data.append(extracted_row)\n",
    "\n",
    "    movies_budget_df = pd.DataFrame(data)\n",
    "    movies_budget_df = movies_budget_df.fillna({\n",
    "        'budget': 0,\n",
    "        'imdb_id': '',\n",
    "        'title': ''\n",
    "    })\n",
    "\n",
    "    # merge movie budget with id\n",
    "    link_df = pd.read_csv(\"./data/links.csv\")\n",
    "    link_df['imdbId'] = link_df['imdbId'].apply(lambda x: f'tt0{int(x)}')\n",
    "\n",
    "    movies_id_df = pd.merge(movies_budget_df, link_df, left_on='imdb_id', right_on='imdbId', how='inner')\n",
    "    movies_id_df['budget'] = pd.to_numeric(movies_id_df['budget'])\n",
    "    movies_id_df['revenue'] = pd.to_numeric(movies_id_df['revenue'])\n",
    "    movies_id_df = movies_id_df[movies_id_df.budget != 0]\n",
    "    movies_id_df = movies_id_df[movies_id_df.revenue != 0]\n",
    "\n",
    "    movies_info_df = pd.read_csv(\"./data/movies.csv\")\n",
    "    movies_df = pd.merge(movies_id_df, movies_info_df, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    ratings_df = pd.read_csv(\"./data/ratings.csv\")\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(movies_df['movieId'])]\n",
    "\n",
    "    return movies_df, ratings_df\n",
    "\n",
    "movies_df, ratings_df = read_movies()\n",
    "print(movies_df.head())\n",
    "print(ratings_df.head())\n",
    "print(len(movies_df))\n",
    "print(len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the relations\n",
    "user_movie_rating_triples = []\n",
    "for index, row in ratings_df.iterrows():\n",
    "    user_movie_rating_triples.append((f\"user_{row['userId']}\", f\"rated_{row['rating']}\", f\"movie_{row['movieId']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_budget_triples = []\n",
    "movie_revenue_triples = []\n",
    "movie_ratings_triples = []\n",
    "for index, row in movies_df.iterrows():\n",
    "    movie_budget_triples .append((f\"movie_{row['movieId']}\", \"used_budget\", f\"budget_{row['budget']}\"))\n",
    "    movie_revenue_triples.append((f\"movie_{row['movieId']}\", \"used_revenue\", f\"revenue_{row['revenue']}\"))\n",
    "    movie_ratings_triples.append((f\"movie_{row['movieId']}\", \"used_ratings\", f\"ratings_{row['vote_average']}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          head     relation             tail\n",
      "0  movie_82167  used_budget  budget_30000000\n",
      "1  movie_48239  used_budget   budget_4600000\n",
      "2  movie_79879  used_budget  budget_24000000\n",
      "3  movie_59366  used_budget    budget_600000\n",
      "4   movie_8996  used_budget  budget_16000000\n"
     ]
    }
   ],
   "source": [
    "def triple_df(head, relation, tail):\n",
    "    return pd.DataFrame({\n",
    "        'head': head,\n",
    "        'relation': relation,\n",
    "        'tail': tail\n",
    "    })\n",
    "\n",
    "# Correct way to create the Series for head and tail\n",
    "head_series = 'movie_' + movies_df['movieId'].astype(str)\n",
    "tail_series_budget = 'budget_' + movies_df['budget'].astype(str)\n",
    "tail_series_revenue = 'revenue_' + movies_df['revenue'].astype(str)\n",
    "tail_series_ratings = 'avgrating_' + movies_df['vote_average'].astype(str)\n",
    "head_series_users = 'user_' + ratings_df['userId'].astype(str)\n",
    "tail_series_individual_movie_rating = 'rating'\n",
    "\n",
    "# Use the function with the corrected series\n",
    "movie_budget_triples = triple_df(head_series, 'used_budget', tail_series_budget)\n",
    "movie_revenue_triples = triple_df(head_series, 'used_revenue', tail_series_revenue)\n",
    "movie_ratings_triples = triple_df(head_series, 'used_avgrating', tail_series_ratings)\n",
    "\n",
    "# If you want to concatenate them into one DataFrame:\n",
    "all_triples_df = pd.concat([movie_budget_triples, movie_revenue_triples, movie_ratings_triples], ignore_index=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(all_triples_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=440209930\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# the split should be done not over all the triples but for each relation triples. So that the training data is kinda balanced\n",
    "triples_array = all_triples_df[['head', 'relation', 'tail']].to_numpy()\n",
    "\n",
    "# Create a TriplesFactory from the numpy array\n",
    "tf = TriplesFactory.from_labeled_triples(triples_array)\n",
    "\n",
    "# Optionally, split the data into training, testing, and validation sets\n",
    "training, testing, validation = tf.split([0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No cuda devices were available. The model runs on CPU\n",
      "Training epochs on cpu:   4%|▍         | 4/100 [00:03<01:34,  1.02epoch/s, loss=0.734, prev_loss=0.838]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f0c532ca0c0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/piragi/Documents/Uni/knowledge_graphs/kg-env/lib64/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Training epochs on cpu: 100%|██████████| 100/100 [01:37<00:00,  1.03epoch/s, loss=0.0144, prev_loss=0.0114]\n",
      "Evaluating on cpu:   0%|          | 0.00/896 [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 896/896 [00:01<00:00, 557triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.63s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineResult(random_seed=42, model=TransE(\n",
      "  (loss): MarginRankingLoss(\n",
      "    (margin_activation): ReLU()\n",
      "  )\n",
      "  (interaction): TransEInteraction()\n",
      "  (entity_representations): ModuleList(\n",
      "    (0): Embedding(\n",
      "      (_embeddings): Embedding(6357, 50)\n",
      "    )\n",
      "  )\n",
      "  (relation_representations): ModuleList(\n",
      "    (0): Embedding(\n",
      "      (_embeddings): Embedding(3, 50)\n",
      "    )\n",
      "  )\n",
      "  (weight_regularizers): ModuleList()\n",
      "), training=TriplesFactory(num_entities=6357, num_relations=3, create_inverse_triples=False, num_triples=7166), training_loop=<pykeen.training.slcwa.SLCWATrainingLoop object at 0x7f0a283e6bd0>, losses=[1.0749339248452867, 0.940182055745806, 0.8377121942383903, 0.7343105013881411, 0.6503036575657981, 0.5685225884829249, 0.4995496847799846, 0.450326963194779, 0.41334578501326696, 0.3652692937425205, 0.3340562273349081, 0.2986153555767877, 0.2762088844818728, 0.2546400363956179, 0.2304127620799201, 0.2083234116435051, 0.1927810843501772, 0.17360497372491018, 0.1675507857331208, 0.14842185963477408, 0.14475721732846328, 0.14369841718247958, 0.12350420893302985, 0.11624826091740813, 0.11370451987854072, 0.10490985347756318, 0.10250816281352725, 0.09894109331071377, 0.09402304462024144, 0.08005562704056501, 0.07686422831778016, 0.07464973482170276, 0.07124145235866308, 0.06809049392385143, 0.06544813300882067, 0.060319368195320876, 0.057156041996287446, 0.06354717896985156, 0.054372004233300686, 0.05357125135404723, 0.05054186983034015, 0.04726234583982399, 0.046065683609672954, 0.044076416841042895, 0.04129720226462398, 0.04003115111429777, 0.0380844259634614, 0.03548368266118424, 0.03736794161211167, 0.03330715998475041, 0.033445322287401984, 0.03020440654030868, 0.030700165312737226, 0.02991118554824165, 0.025842612542744194, 0.027495330332645347, 0.027109184568481787, 0.025325304362922907, 0.026520620499338423, 0.0234563757133271, 0.02099324789430414, 0.024701882985287478, 0.023848589908863817, 0.02468224867646183, 0.02313851465338043, 0.02103172375687531, 0.022402611827211722, 0.01956684687840087, 0.018174688065690652, 0.016557114997080395, 0.017613209784030914, 0.019599226902105978, 0.017571134958416224, 0.016408390698156188, 0.016517952483679568, 0.017263037086065327, 0.017172365183276788, 0.016889471361147507, 0.018733972051580037, 0.01484209784705724, 0.013210885958479983, 0.01450305781327188, 0.013458762051803725, 0.014100396107616169, 0.014570782360221659, 0.014647930993565492, 0.012398201672892486, 0.01291161506170673, 0.013310702168382704, 0.014140632119961083, 0.013811238326265343, 0.011351235177634018, 0.012811163506869758, 0.012472916128379958, 0.011317109622593437, 0.012911928701214492, 0.011552684308428849, 0.011991092170189534, 0.011369624308177404, 0.014440523028107626], metric_results=<pykeen.evaluation.rank_based_evaluator.RankBasedMetricResults object at 0x7f09d7602120>, train_seconds=98.05348467826843, evaluate_seconds=1.6267781257629395, stopper=<pykeen.stoppers.stopper.NopStopper object at 0x7f09d7b359a0>, configuration={'dataset': '<user defined>', 'training': '<user defined>', 'testing': '<user defined>', 'validation': '<user defined>', 'model': 'TransE', 'model_kwargs': {'random_seed': 42, 'loss': MarginRankingLoss(\n",
      "  (margin_activation): ReLU()\n",
      "), 'embedding_dim': 50, 'scoring_fct_norm': 1, 'entity_initializer': <function xavier_uniform_ at 0x7f09e7923ec0>, 'entity_constrainer': <function normalize at 0x7f0a9615d760>, 'relation_initializer': <pykeen.utils.compose object at 0x7f09e7aa6a50>, 'relation_constrainer': None, 'regularizer': None, 'regularizer_kwargs': None}, 'loss_kwargs': None, 'regularizer_kwargs': None, 'optimizer': 'Adam', 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}, 'training_loop': 'SLCWATrainingLoop', 'training_loop_kwargs': {}, 'evaluator': 'RankBasedEvaluator', 'evaluator_kwargs': {}, 'num_epochs': 100, 'batch_size': 256, 'evaluation_kwargs': {'additional_filter_triples': {'training': {'sha512': '5c7f4f050d42cfb737d98b299aae5398c9a95f621339a291725b87f3ee0f1528661cf5ff82f303062b858c166289d73ffff2b41c1c9d13dba8793de15cfd9e8c'}, 'validation': {'sha512': '5901e08b7ff5f1456ae0d19c23bb753fe9aefb19746ea314fb75d97372417f0576acb2095fea8ba8f2cc0caca61165775b020fee382ff8e0d5b51d6fee636212'}}}}, metadata={}, version='1.10.2', git_hash='UNHASHED')\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Configure and run the pipeline\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model='TransE',  # You can choose other models like DistMult, ComplEx, etc.\n",
    "    training_kwargs={'num_epochs': 1, 'batch_size': 256},  # Adjust these parameters as needed\n",
    "    random_seed=42,\n",
    "    device='cuda'  # Use 'cuda' if you have a GPU, otherwise use 'cpu'\n",
    ")\n",
    "\n",
    "# Access the results\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
