{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "5       1       70     3.0  964982400\n",
      "2427\n",
      "55445\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(500)\n",
    "\n",
    "from torch import Tensor\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_movies():\n",
    "    # read csv with movies for budget and imdb_id\n",
    "    columns_of_interest = ['budget', 'imdb_id', 'revenue', 'vote_average', 'directors', 'vote_count']\n",
    "    data = []\n",
    "    with open('./data/movie_data_tmbd.csv', 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter='|')\n",
    "        for row in reader:\n",
    "            extracted_row = {col: row[col] for col in columns_of_interest}\n",
    "            data.append(extracted_row)\n",
    "\n",
    "    movies_budget_df = pd.DataFrame(data)\n",
    "    movies_budget_df = movies_budget_df.fillna({\n",
    "        'budget': 0,\n",
    "        'imdb_id': '',\n",
    "        'title': '',\n",
    "        'director': '',\n",
    "        'revenue': 0,\n",
    "        'vote_count': 0,\n",
    "    })\n",
    "\n",
    "    # merge movie budget with id\n",
    "    link_df = pd.read_csv(\"./data/small/links.csv\")\n",
    "    link_df['imdbId'] = link_df['imdbId'].apply(lambda x: f'tt0{int(x)}')\n",
    "\n",
    "    movies_id_df = pd.merge(movies_budget_df, link_df, left_on='imdb_id', right_on='imdbId', how='inner')\n",
    "    movies_id_df['budget'] = pd.to_numeric(movies_id_df['budget'])\n",
    "    movies_id_df['revenue'] = pd.to_numeric(movies_id_df['revenue'])\n",
    "    movies_id_df['vote_count'] = pd.to_numeric(movies_id_df['vote_count'])\n",
    "    movies_id_df = movies_id_df[movies_id_df.budget != 0]\n",
    "    movies_id_df = movies_id_df[movies_id_df.revenue != 0]\n",
    "\n",
    "    movies_info_df = pd.read_csv(\"./data/small/movies.csv\")\n",
    "    movies_df = pd.merge(movies_id_df, movies_info_df, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "    ratings_df = pd.read_csv(\"./data/small/ratings.csv\")\n",
    "    #ratings_df = ratings_df.iloc[:ratings_df.shape[0]//10]\n",
    "    ratings_df = ratings_df[ratings_df['movieId'].isin(movies_df['movieId'])]\n",
    "\n",
    "    return movies_df, ratings_df\n",
    "\n",
    "movies_df, ratings_df = read_movies()\n",
    "#print(movies_df.head())\n",
    "print(ratings_df.head())\n",
    "print(len(movies_df))\n",
    "print(len(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2427, 23])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2152/3551655568.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  movies_df['vote_average'].fillna(5.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "genres = movies_df['genres'].str.get_dummies('|')\n",
    "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
    "movies_df['vote_average'].fillna(5.0, inplace=True)\n",
    "\n",
    "vote_average = torch.from_numpy(movies_df['vote_average'].astype(float).values).to(torch.float).unsqueeze(-1)\n",
    "revenue = torch.from_numpy(movies_df['revenue'].values).to(torch.float).unsqueeze(-1)\n",
    "budget = torch.from_numpy(movies_df['budget'].values).to(torch.float).unsqueeze(-1)\n",
    "vote_count = torch.from_numpy(movies_df['vote_count'].values).to(torch.float).unsqueeze(-1)\n",
    "\n",
    "standardize = lambda x: (x - x.mean()) / x.std()\n",
    "\n",
    "vote_average = standardize(vote_average)\n",
    "revenue = standardize(revenue)\n",
    "budget = standardize(budget)\n",
    "vote_count = standardize(vote_count)\n",
    "\n",
    "movie_feat = torch.cat([movie_feat, vote_count, vote_average, revenue, budget], dim=1)\n",
    "\n",
    "print(movie_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "# Check if conversion is needed and perform it safely\n",
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        if isinstance(s, str):\n",
    "            return literal_eval(s)\n",
    "        else:\n",
    "            return s  # assuming s is already the correct format\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "movies_df['directors'] = movies_df['directors'].apply(safe_literal_eval)\n",
    "\n",
    "# Explode the DataFrame on the 'directors' column if the data is correctly formatted as lists of dictionaries\n",
    "directors_expanded = movies_df.explode('directors').dropna()\n",
    "\n",
    "# Normalize the directors' dictionary data into separate DataFrame columns\n",
    "if not directors_expanded['directors'].isnull().all():  # Check if all values are not None\n",
    "    directors_expanded[['director_id', 'director_name']] = directors_expanded['directors'].apply(lambda d: pd.Series({'id': d['id'], 'name': d['name']}) if pd.notna(d) else pd.Series({'id': None, 'name': None}))\n",
    "else:\n",
    "    print(\"No valid director data available.\")\n",
    "\n",
    "directors_expanded['vote_average'] = pd.to_numeric(directors_expanded['vote_average'], errors='coerce')\n",
    "\n",
    "# Group by director name and calculate mean ratings and count of movies\n",
    "director_stats = directors_expanded.groupby('director_name').agg({\n",
    "    'vote_average': ['mean', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-level column headers\n",
    "director_stats.columns = ['director', 'average_rating', 'movie_counts']\n",
    "director_stats = director_stats[['average_rating','movie_counts']]\n",
    "\n",
    "director_stats['average_rating'] = standardize(director_stats['average_rating'])\n",
    "director_stats['movie_counts'] = standardize(director_stats['movie_counts'])\n",
    "director_stats = torch.from_numpy(director_stats.values).to(torch.float)\n",
    "\n",
    "directors_expanded = directors_expanded[['movieId', 'director_name', 'director_id']]\n",
    "movies_extended_df = pd.merge(movies_df, directors_expanded, on='movieId', how='left')\n",
    "movies_extended_df = movies_extended_df.dropna(subset=['director_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_director_id = movies_extended_df['director_id'].unique()\n",
    "unique_director_id = pd.DataFrame(data={\n",
    "    'director_id': unique_director_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_director_id))\n",
    "})\n",
    "unique_movie_id = movies_extended_df['movieId'].unique()\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': unique_movie_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_movie_id))\n",
    "})\n",
    "\n",
    "director_director_id = pd.merge(movies_extended_df['director_id'], unique_director_id, on='director_id', how='left')\n",
    "director_director_id = torch.from_numpy(director_director_id['mappedId'].values)\n",
    "director_movie_id = pd.merge(movies_extended_df['movieId'], unique_movie_id, on='movieId', how='left')\n",
    "director_movie_id = torch.from_numpy(director_movie_id['mappedId'].values)\n",
    "\n",
    "edge_index_director_to_movie = torch.stack([director_director_id, director_movie_id], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a compact representation of the data\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "unique_movie_id = ratings_df['movieId'].unique()\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': unique_movie_id,\n",
    "    'mappedId': pd.RangeIndex(len(unique_movie_id)),\n",
    "})\n",
    "\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id, on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedId'].values)\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id, on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedId'].values)\n",
    "\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[609] },\n",
      "  movie={\n",
      "    node_id=[2427],\n",
      "    x=[2427, 23],\n",
      "  },\n",
      "  director={\n",
      "    node_id=[1229],\n",
      "    x=[1229, 2],\n",
      "  },\n",
      "  (user, rates, movie)={ edge_index=[2, 25903] },\n",
      "  (director, directs, movie)={ edge_index=[2, 2605] },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 25903] },\n",
      "  (movie, rev_directs, director)={ edge_index=[2, 2605] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "# save node indices\n",
    "data['user'].node_id = torch.arange(len(unique_user_id))\n",
    "data['movie'].node_id = torch.arange(len(unique_movie_id))\n",
    "data['director'].node_id = torch.arange(len(unique_director_id))\n",
    "\n",
    "# add node features\n",
    "data['movie'].x = movie_feat\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index_user_to_movie\n",
    "\n",
    "data['user', 'rates', 'movie'].edge_label = torch.from_numpy(ratings_df['rating'].values).to(torch.long) # TODO: this cuts off the .5 steps\n",
    "mask = data['user', 'rates', 'movie'].edge_label >= 4\n",
    "del data['user', 'rates', 'movie'].edge_label \n",
    "data['user', 'rates', 'movie'].edge_index = data['user', 'rates', 'movie'].edge_index[:, mask]\n",
    "\n",
    "data['director'].x = director_stats\n",
    "data['director', 'directs', 'movie'].edge_index = edge_index_director_to_movie\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[(\"user\", \"rates\", \"movie\"), (\"director\", \"directs\", \"movie\")],\n",
    "    rev_edge_types=[(\"movie\", \"rev_rates\", \"user\"), (\"movie\", \"rev_directs\", \"director\")],\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "# Example configuration with correct tuple formatting for edge_label_index:\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[10,10,10],\n",
    "    edge_label_index=(('user', 'rates', 'movie'), train_data['user', 'rates', 'movie'].edge_label_index),  # Correct tuple format\n",
    "    edge_label=train_data['user', 'rates', 'movie'].edge_label,  # Labels for the edges\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    neg_sampling_ratio=2.0  # Example negative sampling ratio\n",
    ")\n",
    "\n",
    "# Define the validation seed edges:\n",
    "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[10,10,10],\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128*3,\n",
    "    shuffle=False,\n",
    ")\n",
    "print(next(iter(train_loader))['user', 'rates', 'movie'].edge_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (movie_lin): Linear(in_features=23, out_features=128, bias=True)\n",
      "  (director_lin): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (user_emb): Embedding(609, 128)\n",
      "  (movie_emb): Embedding(2427, 128)\n",
      "  (director_emb): Embedding(1229, 128)\n",
      "  (gnn): GraphModule(\n",
      "    (conv): ModuleList(\n",
      "      (0-1): 2 x ModuleDict(\n",
      "        (user__rates__movie): SAGEConv(128, 128, aggr=mean)\n",
      "        (director__directs__movie): SAGEConv(128, 128, aggr=mean)\n",
      "        (movie__rev_rates__user): SAGEConv(128, 128, aggr=mean)\n",
      "        (movie__rev_directs__director): SAGEConv(128, 128, aggr=mean)\n",
      "      )\n",
      "    )\n",
      "    (batch_norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GraphConv, to_hetero, SAGEConv, GraphSAGE\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, layers):\n",
    "        super().__init__()\n",
    "        input_dim = num_features\n",
    "        self.conv = torch.nn.ModuleList()\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(hidden_dim)\n",
    "        for _ in range(layers):\n",
    "            self.conv.append(SAGEConv(input_dim, hidden_dim))\n",
    "            input_dim = hidden_dim\n",
    "    \n",
    "    def forward(self, x, edge_index):#, edge_weight):\n",
    "        for layer in self.conv:\n",
    "            x = layer(x, edge_index)\n",
    "            # x = torch.dropout(x, 0.1, True)\n",
    "            # x = self.batch_norm(x)\n",
    "            x = torch.relu(x)\n",
    "        return x\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(2*hidden_dim, hidden_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)  # Final layer for link prediction\n",
    "\n",
    "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Extract features for users and movies according to the edge indices\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "\n",
    "        # Concatenate user and movie features\n",
    "        x = torch.cat((edge_feat_user, edge_feat_movie), dim=1)  # Concatenation along the feature dimension\n",
    "\n",
    "        # Pass the concatenated vector through the dense layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    # TODO: add data in function header?\n",
    "    def __init__(self, num_features, hidden_dim, layers):\n",
    "        super().__init__()\n",
    "        self.movie_lin = torch.nn.Linear(23, hidden_dim) # TODO: thats the number of neighbors?\n",
    "        self.director_lin = torch.nn.Linear(2, hidden_dim)\n",
    "        self.user_emb = torch.nn.Embedding(data['user'].num_nodes, hidden_dim)\n",
    "        self.movie_emb = torch.nn.Embedding(data['movie'].num_nodes, hidden_dim)\n",
    "        self.director_emb = torch.nn.Embedding(data['director'].num_nodes, hidden_dim)\n",
    "        self.gnn = GNN(num_features, hidden_dim, layers)\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata(), aggr='sum')\n",
    "        self.classifier = Classifier(hidden_dim)\n",
    "\n",
    "    def forward(self, data:HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "            \"user\": self.user_emb(data['user'].node_id),\n",
    "            \"movie\": self.movie_lin(data['movie'].x) + self.movie_emb(data['movie'].node_id),\n",
    "            \"director\": self.director_lin(data['director'].x) + self.director_emb(data['director'].node_id) \n",
    "        }\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)#, data.edge_weight_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"movie\"],\n",
    "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
    "        )\n",
    "        return pred\n",
    "\n",
    "model = Model(128, 128, 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Epoch 001, Loss: 1.5788, Validation AUC: 0.8575\n",
      "Epoch 011, Loss: 0.9019, Validation AUC: 0.8861\n",
      "Epoch 021, Loss: 0.7846, Validation AUC: 0.8888\n",
      "Epoch 031, Loss: 0.7224, Validation AUC: 0.8956\n",
      "Epoch 041, Loss: 0.6396, Validation AUC: 0.8954\n",
      "Epoch 051, Loss: 0.5799, Validation AUC: 0.8985\n",
      "Epoch 061, Loss: 0.5139, Validation AUC: 0.8985\n",
      "Epoch 071, Loss: 0.5000, Validation AUC: 0.8975\n",
      "Epoch 081, Loss: 0.4428, Validation AUC: 0.8994\n",
      "Epoch 091, Loss: 0.4433, Validation AUC: 0.8964\n",
      "Epoch 101, Loss: 0.4171, Validation AUC: 0.8978\n",
      "Epoch 111, Loss: 0.4316, Validation AUC: 0.8974\n",
      "Epoch 121, Loss: 0.4043, Validation AUC: 0.8978\n",
      "Epoch 131, Loss: 0.3561, Validation AUC: 0.8957\n",
      "Epoch 141, Loss: 0.3458, Validation AUC: 0.8947\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "#model = torch.load(\"./model/auc_8092.pt\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "save = False\n",
    "\n",
    "\n",
    "for epoch in range(150):\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    model.train()\n",
    "    for train_sample in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        train_sample.to(device)\n",
    "        pred = model(train_sample)\n",
    "        label = train_sample['user', 'rates', 'movie'].edge_label\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * label.size(0) # TODO: numel?!\n",
    "        total_examples += label.size(0)\n",
    "\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ground_truths = []\n",
    "    for sampled_data in val_loader:\n",
    "        with torch.no_grad():\n",
    "            sampled_data.to(device)\n",
    "            preds.append(model(sampled_data))\n",
    "            ground_truths.append(sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
    "    #pred = torch.sigmoid(pred)\n",
    "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "    auc = roc_auc_score(ground_truth, pred)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1:03d}, Loss: {total_loss / len(train_loader.dataset):.4f}, Validation AUC: {auc:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "if save: torch.save(model, f\"./model/auc_{int(auc*10000)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
